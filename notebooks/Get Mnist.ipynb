{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "from subprocess import call\n",
    "from urllib import urlretrieve\n",
    "import os\n",
    "import gzip\n",
    "import binascii\n",
    "import struct\n",
    "import numpy\n",
    "import sys\n",
    "from matplotlib import pyplot\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "save_dir = '/notebooks/mnist'\n",
    "\n",
    "filenames = [\n",
    "    'train-images-idx3-ubyte.gz', #:  training set images (9912422 bytes) \n",
    "    'train-labels-idx1-ubyte.gz', #:  training set labels (28881 bytes) \n",
    "    't10k-images-idx3-ubyte.gz',  #:   test set images (1648877 bytes) \n",
    "    't10k-labels-idx1-ubyte.gz'   #:   test set labels (4542 bytes)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grab the MNist files..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path /notebooks/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz ...\n",
      "... done\n",
      "Path /notebooks/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz ...\n",
      "... done\n",
      "Path /notebooks/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz ...\n",
      "... done\n",
      "Path /notebooks/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz ...\n",
      "... done\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "for f in filenames:\n",
    "    fullpath = os.path.join(save_dir, f)\n",
    "    downloadurl = 'http://yann.lecun.com/exdb/mnist/' + f\n",
    "    print \"Path\", fullpath\n",
    "    if os.path.exists(fullpath):\n",
    "        print \"Nothing to do.\"\n",
    "    else:\n",
    "        print \"Downloading\", downloadurl, \"...\"\n",
    "        urlretrieve(downloadurl, fullpath)\n",
    "        print \"... done\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data file and parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unpacking image train-images-idx3-ubyte.gz ...\n",
      "Reading 60000 images:\n",
      "............................................................done\n",
      "Unpacking labels train-labels-idx1-ubyte.gz ...\n",
      "Reading 60000 labels:\n",
      "... done\n",
      "Unpacking image t10k-images-idx3-ubyte.gz ...\n",
      "Reading 10000 images:\n",
      "..........done\n",
      "Unpacking labels t10k-labels-idx1-ubyte.gz ...\n",
      "Reading 10000 labels:\n",
      "... done\n",
      "##Training"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'count'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-f079337aa2a1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     80\u001b[0m }\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m \u001b[1;32mprint\u001b[0m \u001b[1;34m\"##Training\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'image_fields'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'count'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"images:\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m \u001b[0mpyplot_images\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'image'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'image'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'image'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[1;34m\"##Testing\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtesting\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'image_fields'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'count'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"images:\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'count'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "def progress_dot():\n",
    "    sys.stdout.write('.')\n",
    "    sys.stdout.flush()\n",
    "\n",
    "def unpack_int(data_file):\n",
    "    data = data_file.read(4)\n",
    "    data = struct.unpack('>i', data)[0]\n",
    "    return data\n",
    "\n",
    "def unpack_image(data_file):\n",
    "    img = data_file.read(28 * 28)\n",
    "    img = struct.unpack('B' * (28 * 28), img)\n",
    "    img = numpy.array(img)\n",
    "    img = (img - 128) / 255.0\n",
    "    return img\n",
    "\n",
    "def pyplot_images(image_list):\n",
    "    histogram = len(image_list) == 1\n",
    "    plot_count = 2 if histogram else len(image_list)\n",
    "    _, plots = pyplot.subplots(1, plot_count)\n",
    "    for i in range(len(image_list)):\n",
    "        img = image_list[i]\n",
    "        plot = plots[i]\n",
    "        plot.imshow(img.reshape(28, 28), cmap=pyplot.cm.Greys)\n",
    "        if histogram:\n",
    "            histplot = plots[i + 1]\n",
    "            histplot.hist(img, bins=20, range=[-1.0,1.0])\n",
    "\n",
    "def unpack_image_data(filename):\n",
    "    print \"Unpacking image\", filename, \"...\"\n",
    "    with gzip.open(os.path.join(save_dir, filename)) as data_file:\n",
    "        fields = {\n",
    "            'magic_number': unpack_int(data_file),\n",
    "            'image_count': unpack_int(data_file),\n",
    "            'rows': unpack_int(data_file),\n",
    "            'columns': unpack_int(data_file),\n",
    "        }\n",
    "        image_count = fields['image_count']\n",
    "        image_list = []\n",
    "        print \"Reading\", image_count, \"images:\"\n",
    "        while(image_count > len(image_list)):\n",
    "            if(len(image_list) % 1000 == 0):\n",
    "                progress_dot()\n",
    "            img = unpack_image(data_file)\n",
    "            image_list.append(img)\n",
    "        print \"done\"\n",
    "        return fields, image_list\n",
    "\n",
    "def unpack_labels(filename):\n",
    "    print \"Unpacking labels\", filename, \"...\"\n",
    "    with gzip.open(os.path.join(save_dir, filename)) as data_file:\n",
    "        fields = {\n",
    "            'magic_number': unpack_int(data_file),\n",
    "            'label_count': unpack_int(data_file)\n",
    "        }\n",
    "        print \"Reading\", fields['label_count'], 'labels:'\n",
    "        label_data = data_file.read(fields['label_count'])\n",
    "        label_list = struct.unpack('B' * fields['label_count'], label_data)\n",
    "    print \"... done\"\n",
    "    return fields, label_list\n",
    "\n",
    "image_fields, image_list = unpack_image_data('train-images-idx3-ubyte.gz')\n",
    "label_fields, label_list = unpack_labels('train-labels-idx1-ubyte.gz')\n",
    "training = {\n",
    "    'image_fields': image_fields,\n",
    "    'image': image_list,\n",
    "    'label_fields': label_fields,\n",
    "    'label': label_list\n",
    "}\n",
    "\n",
    "image_fields, image_list = unpack_image_data('t10k-images-idx3-ubyte.gz')\n",
    "label_fields, label_list = unpack_labels('t10k-labels-idx1-ubyte.gz')\n",
    "testing = {\n",
    "    'image_fields': image_fields,\n",
    "    'image': image_list,\n",
    "    'label_fields': label_fields,\n",
    "    'label': label_list\n",
    "}\n",
    "\n",
    "print \"##Training\", training['image_fields']['count'], \"images:\"\n",
    "pyplot_images([training['image'][0], training['image'][1], training['image'][2]])\n",
    "print \"##Testing\", testing['image_fields']['count'], \"images:\"\n",
    "pyplot_images([testing['image'][0], testing['image'][1], testing['image'][2]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "\n",
    "x = tensorflow.placeholder(tensorflow.float, [None, 28 * 28])\n",
    "w = tensorflow.Variable(tensorflow.zeros([784, 10]))\n",
    "b = tensorflow.Variable(tensorflow.zeros([10]))\n",
    "y = tensorflow.nn.softmax(tensorflow.matmul(x, w) + b)\n",
    "y_ = tensorflow.placeholder(tensorflow.float, [None, 10])\n",
    "cross_entropy = tensorflow.reduce_mean(-tensorflow.reduce_sum(y_ * tensorflow.log(y), reduction_indices=[1]))\n",
    "\n",
    "train_step = tensorflow.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    "init = tensorflow.init_all_variables();\n",
    "sess = tensorflow.Session()\n",
    "sess.run(init)\n",
    "\n",
    "for i in range(1000):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## FOOBAR"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
